# utils/cache.py
"""
æ•°æ®ç¼“å­˜æ¨¡å—
ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œå‡å°‘APIè°ƒç”¨
"""
import pandas as pd
import os
import json
from datetime import datetime
from pathlib import Path


class DataCache:
    """æ•°æ®ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir='data_cache'):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Parameters:
        -----------
        cache_dir : str
            ç¼“å­˜ç›®å½•è·¯å¾„
        """
        self.cache_dir = Path(cache_dir)
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        if not self.cache_dir.exists():
            self.cache_dir.mkdir(parents=True, exist_ok=True)
            print(f"âœ… åˆ›å»ºç¼“å­˜ç›®å½•: {self.cache_dir}")
        
        # å…ƒæ•°æ®æ–‡ä»¶
        self.metadata_file = self.cache_dir / 'cache_metadata.json'
        self.metadata = self._load_metadata()
    
    def _load_metadata(self):
        """åŠ è½½ç¼“å­˜å…ƒæ•°æ®"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
                return {}
        return {}
    
    def _save_metadata(self):
        """ä¿å­˜ç¼“å­˜å…ƒæ•°æ®"""
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
    
    def _get_cache_key(self, stock_code, start_date, end_date):
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{stock_code}_{start_date}_{end_date}"
    
    def _get_cache_path(self, stock_code, start_date, end_date):
        """ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        cache_key = self._get_cache_key(stock_code, start_date, end_date)
        filename = f"{cache_key}.csv"
        return self.cache_dir / filename
    
    def get_prices(self, stock_code, start_date, end_date):
        """
        ä»ç¼“å­˜åŠ è½½ä»·æ ¼æ•°æ®
        
        Parameters:
        -----------
        stock_code : str
            è‚¡ç¥¨ä»£ç 
        start_date : str
            å¼€å§‹æ—¥æœŸ 'YYYY-MM-DD'
        end_date : str
            ç»“æŸæ—¥æœŸ 'YYYY-MM-DD'
        
        Returns:
        --------
        DataFrame or None : ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        cache_path = self._get_cache_path(stock_code, start_date, end_date)
        cache_key = self._get_cache_key(stock_code, start_date, end_date)
        
        if not cache_path.exists():
            return None
        
        try:
            # è¯»å–CSV
            df = pd.read_csv(cache_path)
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if 'date' not in df.columns:
                print(f"âš ï¸  ç¼“å­˜æ•°æ®æ ¼å¼é”™è¯¯ï¼ˆç¼ºå°‘dateåˆ—ï¼‰: {cache_key}")
                return None
            
            # æ£€æŸ¥ç¼“å­˜æ—¶é—´
            if cache_key in self.metadata:
                cache_time = self.metadata[cache_key].get('cached_at', '')
                rows = len(df)
                print(f"ğŸ“ ä½¿ç”¨ç¼“å­˜: {stock_code} ({rows}è¡Œ) [ç¼“å­˜äº {cache_time}]")
            else:
                print(f"ğŸ“ ä½¿ç”¨ç¼“å­˜: {stock_code} ({len(df)}è¡Œ)")
            
            return df
            
        except Exception as e:
            print(f"âš ï¸  è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            # åˆ é™¤æŸåçš„ç¼“å­˜
            try:
                cache_path.unlink()
                if cache_key in self.metadata:
                    del self.metadata[cache_key]
                    self._save_metadata()
            except:
                pass
            return None
    
    def set_prices(self, stock_code, df, start_date=None, end_date=None):
        """
        ä¿å­˜ä»·æ ¼æ•°æ®åˆ°ç¼“å­˜
        
        Parameters:
        -----------
        stock_code : str
            è‚¡ç¥¨ä»£ç 
        df : DataFrame
            ä»·æ ¼æ•°æ®
        start_date : str, optional
            å¼€å§‹æ—¥æœŸï¼ˆå¦‚æœNoneï¼Œä»æ•°æ®ä¸­æå–ï¼‰
        end_date : str, optional
            ç»“æŸæ—¥æœŸï¼ˆå¦‚æœNoneï¼Œä»æ•°æ®ä¸­æå–ï¼‰
        """
        if df is None or len(df) == 0:
            return
        
        try:
            # éªŒè¯æ•°æ®æ ¼å¼
            if 'date' not in df.columns:
                print(f"âš ï¸  æ•°æ®ç¼ºå°‘dateåˆ—ï¼Œæ— æ³•ç¼“å­˜")
                return
            
            # ä»æ•°æ®ä¸­æå–æ—¥æœŸèŒƒå›´
            if start_date is None:
                start_date = df['date'].iloc[0]
            if end_date is None:
                end_date = df['date'].iloc[-1]
            
            cache_path = self._get_cache_path(stock_code, start_date, end_date)
            cache_key = self._get_cache_key(stock_code, start_date, end_date)
            
            # ä¿å­˜CSV
            df.to_csv(cache_path, index=False)
            
            # æ›´æ–°å…ƒæ•°æ®
            self.metadata[cache_key] = {
                'stock_code': stock_code,
                'start_date': start_date,
                'end_date': end_date,
                'rows': len(df),
                'cached_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'file_path': str(cache_path)
            }
            self._save_metadata()
            
            print(f"ğŸ’¾ å·²ç¼“å­˜: {stock_code} ({len(df)}è¡Œ) â†’ {cache_path.name}")
            
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def clear_cache(self, stock_code=None):
        """
        æ¸…é™¤ç¼“å­˜
        
        Parameters:
        -----------
        stock_code : str, optional
            å¦‚æœæŒ‡å®šï¼Œåªæ¸…é™¤è¯¥è‚¡ç¥¨çš„ç¼“å­˜ï¼›å¦åˆ™æ¸…é™¤æ‰€æœ‰
        """
        if stock_code:
            # æ¸…é™¤ç‰¹å®šè‚¡ç¥¨çš„ç¼“å­˜
            removed = 0
            for cache_key in list(self.metadata.keys()):
                if self.metadata[cache_key]['stock_code'] == stock_code:
                    file_path = Path(self.metadata[cache_key]['file_path'])
                    if file_path.exists():
                        file_path.unlink()
                    del self.metadata[cache_key]
                    removed += 1
            
            if removed > 0:
                self._save_metadata()
                print(f"âœ… å·²æ¸…é™¤ {stock_code} çš„ {removed} ä¸ªç¼“å­˜")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ° {stock_code} çš„ç¼“å­˜")
        else:
            # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
            count = 0
            for file in self.cache_dir.glob('*.csv'):
                file.unlink()
                count += 1
            
            self.metadata.clear()
            self._save_metadata()
            print(f"âœ… å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜ ({count} ä¸ªæ–‡ä»¶)")
    
    def list_cache(self):
        """åˆ—å‡ºæ‰€æœ‰ç¼“å­˜"""
        if not self.metadata:
            print("ğŸ“­ ç¼“å­˜ä¸ºç©º")
            return
        
        print(f"\n{'='*70}")
        print(f"ç¼“å­˜åˆ—è¡¨ ({len(self.metadata)} é¡¹)")
        print(f"{'='*70}")
        print(f"{'è‚¡ç¥¨ä»£ç ':<15} {'æ—¥æœŸèŒƒå›´':<25} {'è¡Œæ•°':<8} {'ç¼“å­˜æ—¶é—´':<20}")
        print(f"{'-'*70}")
        
        for cache_key, info in sorted(self.metadata.items()):
            stock = info['stock_code']
            date_range = f"{info['start_date']} ~ {info['end_date']}"
            rows = info['rows']
            cached_at = info['cached_at']
            print(f"{stock:<15} {date_range:<25} {rows:<8} {cached_at:<20}")
        
        print(f"{'='*70}\n")
    
    def get_cache_size(self):
        """è·å–ç¼“å­˜æ€»å¤§å°"""
        total_size = 0
        for file in self.cache_dir.glob('*.csv'):
            total_size += file.stat().st_size
        
        # è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
        if total_size < 1024:
            return f"{total_size} B"
        elif total_size < 1024 * 1024:
            return f"{total_size / 1024:.2f} KB"
        else:
            return f"{total_size / (1024 * 1024):.2f} MB"


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    cache = DataCache()
    
    print("\n" + "="*70)
    print("æ•°æ®ç¼“å­˜æµ‹è¯•")
    print("="*70)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'date': ['2025-01-20', '2025-01-21', '2025-01-22'],
        'open': [100.0, 101.0, 102.0],
        'high': [105.0, 106.0, 107.0],
        'low': [99.0, 100.0, 101.0],
        'close': [103.0, 104.0, 105.0],
        'volume': [1000000, 1100000, 1200000]
    })
    
    # æµ‹è¯•ä¿å­˜
    print("\n1. æµ‹è¯•ä¿å­˜ç¼“å­˜")
    cache.set_prices('TEST.STOCK', test_data, '2025-01-20', '2025-01-22')
    
    # æµ‹è¯•è¯»å–
    print("\n2. æµ‹è¯•è¯»å–ç¼“å­˜")
    cached_data = cache.get_prices('TEST.STOCK', '2025-01-20', '2025-01-22')
    if cached_data is not None:
        print(f"   è¯»å–æˆåŠŸ: {len(cached_data)} è¡Œ")
        print(cached_data)
    
    # åˆ—å‡ºç¼“å­˜
    print("\n3. åˆ—å‡ºæ‰€æœ‰ç¼“å­˜")
    cache.list_cache()
    
    # ç¼“å­˜å¤§å°
    print(f"4. ç¼“å­˜æ€»å¤§å°: {cache.get_cache_size()}")
    
    # æ¸…é™¤æµ‹è¯•ç¼“å­˜
    print("\n5. æ¸…é™¤æµ‹è¯•ç¼“å­˜")
    cache.clear_cache('TEST.STOCK')
    
    print("\nâœ… æµ‹è¯•å®Œæˆ\n")
